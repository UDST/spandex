import ConfigParser
import logging
import os
import subprocess

import psycopg2


# Set up logging system.
logging.basicConfig()
logger = logging.getLogger(__name__)


def load_config(config_dir='config'):
    """Returns a ConfigParser object.

    Configuration is loaded from defaults.cfg and user.cfg in config_dir.

    """
    # Load configuration using ConfigParser.
    logger.debug("Loading configuration from %s" % config_dir)
    config = ConfigParser.RawConfigParser()
    try:
        config.read([os.path.join(config_dir, 'defaults.cfg'),
                     os.path.join(config_dir, 'user.cfg')])
        return config
    except ConfigParser.ParsingError:
        logger.exception("Error parsing configuration")
        raise


def logf(level, f):
    """Log each line of a file-like object at the specified severity level."""
    for line in f:
        if line:
            logger.log(level, line.strip())


class DataLoader(object):
    """Data loader class with support for importing shapefiles.

    Some example usage:

        loader = DataLoader()

        # Load data.
        loader.load_shp('parcel/Alameda.shp', 'staging.alameda')

        # Run SQL command.
        with loader.connection.cursor() as cur:
            cur.execute("SELECT DISTINCT luc_desc FROM staging.alameda;")
            rows = cur.fetchall()

        # Commit and close connection.
        loader.close()

    If used in a with statement, the close method is automatically called at
    the end of the with block.

    Methods:
        close:      Commit and close PostgreSQL connection.
        load_shp:   Load a shapefile from the directory into a PostGIS table.

    Attributes:
        connection: psycopg2 connection object.
        directory:  Path to the directory containing the shapefiles.
        srid:       Spatial Reference System Identifier (SRID).

    Constructor arguments:
        config_dir: Path to configuration directory containing default.cfg
                    and/or user.cfg. If None, attributes must be passed as
                    additional constructor arguments. Otherwise, passed
                    attributes override configuration.

    """

    def __init__(self, config_dir='config', connection=None, directory=None,
                 srid=None):
        # If configuration directory is defined, load it.
        if config_dir:
            config = load_config(config_dir)
            db_config = dict(config.items('database'))

        # If constructor arguments are not populated, use configuration.
        if not connection:
            connection = psycopg2.connect(**db_config)
        if not directory:
            directory = config.get('data', 'directory')
        if not srid:
            srid = config.get('data', 'srid')

        # Assign arguments to class attributes.
        self.connection = connection
        if os.path.exists(directory):
            self.directory = directory
        else:
            raise IOError("Directory does not exist: %s" % directory)
        self.srid = int(srid)

    def __enter__(self, *args, **kwargs):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        if exc_value:
            logger.error("Transaction rollback",
                         exc_info=(exc_type, exc_value, traceback))
            self.connection.rollback()
        else:
            self.connection.commit()
        self.connection.close()

    def close(self):
        self.connection.commit()
        return self.connection.close()

    def load_shp(self, filename, table, drop=False, append=False):
        """Load a shapefile from the directory into a PostGIS table.

        This is a Python wrapper for shp2gpsql. shp2pgsql is spawned by
        subprocess. Commands generated by shp2pgsql are executed on a
        psycopg2 cursor object. For performance, the PostgreSQL "dump"
        format is used instead of the default "insert" SQL format.

        Args:
            filename: Shapefile, relative to the data directory.
            table:    PostGIS table name (optionally schema-qualified).
            drop:     Whether to drop a table that already exists.
                      Defaults to False.
            append:   Whether to append to an existing table, instead of
                      creating one. Defaults to False.
        """
        logger.info("Loading table %s from file %s." % (table, filename))
        filepath = os.path.join(self.directory, filename)

        try:
            with self.connection.cursor() as cur:

                if drop:
                    # Drop the existing table.
                    cur.execute('DROP TABLE IF EXISTS %s' % table)

                if not append:
                    # Create the new table itself without adding actual data.
                    create_table = subprocess.Popen(['shp2pgsql', '-p', '-I',
                                                     '-s', str(self.srid),
                                                     filepath, table],
                                                     stdout=subprocess.PIPE,
                                                     stderr=subprocess.PIPE)
                    try:
                        command = ''
                        for line in create_table.stdout:
                            if line and not (line.startswith('BEGIN') or
                                             line.startswith('COMMIT')):
                                command += line
                        cur.execute(command)
                    finally:
                        logf(logging.DEBUG, create_table.stderr)
                    create_table.wait()

                # Append data to existing or newly-created table.
                append_data = subprocess.Popen(['shp2pgsql', '-a', '-D', '-I',
                                                '-s', str(self.srid),
                                                filepath, table],
                                                stdout=subprocess.PIPE,
                                                stderr=subprocess.PIPE)
                try:
                    while True:
                        line = append_data.stdout.readline()
                        if line.startswith('COPY'):
                            break
                    cur.copy_expert(line, append_data.stdout)
                finally:
                    logf(logging.DEBUG, append_data.stderr)
                append_data.wait()

            # Commit when finished.
            self.connection.commit()

        except:
            logger.exception("Transaction rollback")
            self.connection.rollback()
            raise
